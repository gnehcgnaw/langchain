{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question answering over a group chat messages\n",
    "In this tutorial, we are going to use Langchain + Deep Lake with GPT4 to semantically search and ask questions over a group chat.\n",
    "\n",
    "View a working demo [here](https://twitter.com/thisissukh_/status/1647223328363679745)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install --upgrade langchain deeplake openai tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Add API keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-06T06:40:12.676342Z",
     "start_time": "2023-05-06T06:40:12.647272Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from langchain.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.chains import ConversationalRetrievalChain, RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key:')\n",
    "# os.environ['ACTIVELOOP_TOKEN'] = getpass.getpass('Activeloop Token:')\n",
    "# os.environ['ACTIVELOOP_ORG'] = getpass.getpass('Activeloop Org:')\n",
    "load_dotenv()\n",
    "org = os.getenv('ACTIVELOOP_ORG')\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "dataset_path = 'hub://' + org + '/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 2. Create sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你可以使用ChatGPT生成一个示例群聊对话，使用以下提示：\n",
    "```\n",
    "生成一个群聊对话，三个朋友谈论他们的一天，引用真实的地方和虚构的名字。让它尽可能有趣和详细。\n",
    "```\n",
    "我已经在`messages-CN-zh.txt`中生成了这样的聊天。我们可以保持简单，用这个例子来说明。\n",
    "\n",
    "## 3. Ingest chat embeddings\n",
    "\n",
    "We load the messages in the text file, chunk and upload to ActiveLoop Vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-06T06:47:30.263713Z",
     "start_time": "2023-05-06T06:43:37.978095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='当然，以下是 Joey、Rachel 和 Monica 的一段聊天！\\n\\nRachel：嗨，大家，你们今天过得怎么样？\\n\\nJoey：还不错，Rach。我今天去了自然历史博物馆。\\n\\nMonica：哦，我喜欢那个地方！你看到了恐龙展览吗？\\n\\nJoey：是的，太神奇了！他们有一具巨大的霸王龙骨架，我说：“哇，那个家伙有些严重的咬合力！”\\n\\nRachel：（笑）Joey 的经典语录。\\n\\nMonica：那么，Rachel，你今天干了什么？\\n\\nRachel：嗯，我一整天都在 Central Perk 上班。但是不太糟糕，因为 Gunther 让我在拿铁里加了一份浓缩咖啡。\\n\\nJoey：（嘿嘿一笑）这就是我的女孩，总是突破极限。\\n\\nMonica：说到极限，我今天早上去了 Barry 的 Bootcamp，真是疯狂。我感觉我锻炼了身体的每一个肌肉。\\n\\nRachel：啊，我讨厌锻炼。我们能不能谈些更有趣的事情？\\n\\nJoey：我知道什么有趣！我今天见了我的老朋友 Chandler。\\n\\nMonica：Chandler？我好久没见他了！他怎么样？\\n\\nJoey：他很好。他仍然住在 Tulsa，还在那个数据处理公司工作。\\n\\nRachel：（讽刺地）哇，听起来很惊险。\\n\\nJoey：嘿，不要轻视它。Chandler 在那里过得很好。他有房子、有车，还有一只名叫 Yasmine 的宠物鸭子。\\n\\nMonica：（笑）宠物鸭子？只有 Chandler 才会这么做。\\n\\nRachel：你知道更疯狂的是什么吗？我听说 Ross 上周末去参加了毛茸茸动物大会。\\n\\nJoey：（喷出饮料）什么？那太疯狂了！他为什么要这么做？\\n\\nMonica：我不知道，但我听说他穿着像只巨型松鼠。\\n\\nRachel：（笑）我甚至无法想象那会是什么样子。\\n\\nJoey：（摇头）Ross，伙计。他一直有点……奇怪。\\n\\nMonica：（微笑）这就是我们爱他的原因。\\n\\nRachel：（微笑着回应）是啊，他是我们奇怪的小朋友。\\n\\nJoey：（举起酒杯）为奇怪的朋友和快乐的日', metadata={})]\n",
      "Your Deep Lake dataset has been successfully created!\n",
      "The dataset is private so make sure you are logged in!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/gnehcgnaw/data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://gnehcgnaw/data loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating ingest: 100%|██████████| 1/1 [01:37<00:00\n",
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://gnehcgnaw/data', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype     shape     dtype  compression\n",
      "  -------   -------   -------   -------  ------- \n",
      " embedding  generic  (1, 1536)  float32   None   \n",
      "    ids      text     (1, 1)      str     None   \n",
      " metadata    json     (1, 1)      str     None   \n",
      "   text      text     (1, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    }
   ],
   "source": [
    "with open(\"messages-CN-zh.txt\") as f:\n",
    "    state_of_the_union = f.read()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "pages = text_splitter.split_text(state_of_the_union)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "texts = text_splitter.create_documents(pages)\n",
    "\n",
    "print (texts)\n",
    "\n",
    "dataset_path = 'hub://'+org+'/data'\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = DeepLake.from_documents(texts, embeddings, dataset_path=dataset_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ask questions\n",
    "\n",
    "Now we can ask a question and get an answer back with a semantic search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-06T06:58:25.558070Z",
     "start_time": "2023-05-06T06:56:20.014416Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/gnehcgnaw/data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://gnehcgnaw/data loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://gnehcgnaw/data already exists, loading from the storage\n",
      "Dataset(path='hub://gnehcgnaw/data', read_only=True, tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype     shape     dtype  compression\n",
      "  -------   -------   -------   -------  ------- \n",
      " embedding  generic  (1, 1536)  float32   None   \n",
      "    ids      text     (1, 1)      str     None   \n",
      " metadata    json     (1, 1)      str     None   \n",
      "   text      text     (1, 1)      str     None   \n",
      "{'query': '总共几个人', 'result': ' 五个人：Joey、Rachel、Monica、Chandler 和 Ross。'}\n",
      "{'query': '他们讨论了什么？', 'result': ' 他们讨论了 Joey 去参观博物馆、Monica 去参加 Barry 的 Bootcamp 以及 Ross 参加毛茸茸动物大会的故事。'}\n",
      "{'query': 'Joey说了几句话', 'result': ' Joey说了 5 句话。'}\n"
     ]
    }
   ],
   "source": [
    "db = DeepLake(dataset_path=dataset_path, read_only=True, embedding_function=embeddings)\n",
    "\n",
    "# as_retriever 是一个方法，它将DeepLake转换为Retriever对象，该对象可以用于检索\n",
    "retriever = db.as_retriever()\n",
    "# search_kwargs 是一个字典，它将传递给Retriever的search方法 ，distance_metric是用于检索的距离度量， cos是余弦距离\n",
    "retriever.search_kwargs['distance_metric'] = 'cos'\n",
    "# k是检索的数量\n",
    "retriever.search_kwargs['k'] = 4\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=retriever, return_source_documents=False)\n",
    "\n",
    "while True:\n",
    "    query = input(\"Enter query:\")\n",
    "    if query == \"quit\":\n",
    "        break\n",
    "    # The Hungry Lobster\n",
    "    ans = qa({\"query\": query})\n",
    "    print(ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
